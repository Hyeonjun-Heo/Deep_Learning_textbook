{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.1.1 데이터를 사용한 성능 최적화"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 최대한 많은 데이터 수집하기: 일반적으로 딥러닝이나 머신러닝 알고리즘은 데이터 양이 많을수록 성능이 좋다. 따라서 가능한 많은 데이터(빅데이터)를 수집해야 한다.\n",
    "\n",
    "<img src=\"최적화1.jpg\" width=\"400\" height=\"300\"/>\n",
    "\n",
    "* 데이터 생성하기: 많은 데이터를 수집할 수 없다면 데이터를 만들어 사용 가능하다.\n",
    "* 데이터 범위(scale) 조정하기: 활성화 함수로 시그모이드를 사용한다면 데이터셋 범위를 0~1의 값을 갖도록 하고, 하이퍼볼릭 탄젠트를 사용한다면 데이터셋 범위를 -1~1의 값을 갖도록 조정할 수 있다.\n",
    "\n",
    "또한, 정규화, 규제화, 표준화도 성능 향상에 도움이 된다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.1.2 알고리즘을 이용한 성능 최적화"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝과 딥러닝을 위한 알고리즘은 상당히 많다. 따라서 유사한 용도의 알고리즘들을 선택하여 모델을 훈련시켜보고, 최적의 성능을 보이는 알고리즘을 선택해야 한다.  \n",
    "머신 러닝에서는 데이터 분류를 위해서 SVM, K-근접법 이웃 알고리즘들을 선택하옇 훈련시켜 보거나, 시계열 데이터의 경우 7장에서 다룬 RNN, LSTM, GRU등의 알고리즘을 훈련시켜 성능이 가장 좋은 모델을 선택하여 사용한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.1.3 알고리즘 튜닝을 위한 성능 최적화"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능 최적화를 하는데 가장 많은 시간이 소요되는 부분이다.  \n",
    "모델을 하나 선택하여 훈련시키려면 다양한 하이퍼파라미터를 변경하면서 훈련시키고, 최적의 성능을 도출해야 한다.  \n",
    "이때 선택할 수 있는 하이퍼파라미터로는 다음 항목들이 있다.\n",
    "\n",
    "* 진단: 성능 향상이 어느 순간 멈췄다면 원인을 분석해야할 필요가 있다.  문제를 진단하는 데 사용할 수 있는것이 모델에 대한 평가이다. 다음과 같은 평과 결과를 바탕으로 모델이 과적합(over-fitting)인지, 혹은 다른 원인으로 성능 향상에 문제가 있는지에 대한 인사이트를 얻을 수 있다.\n",
    "\n",
    "<img src=\"최적화2.jpg\" width=\"400\" height=\"300\"/>\n",
    "\n",
    "예를 들어 다음과 같은 상황들이 있을 수 있다.\n",
    "* 훈련(training) 성능이 검증(test)보다 눈에 띄게 좋다면 과적합을 의심해 볼 수 있으며, 이것을 해결하기 위해 규제화를 진행한다면 성능 향상에 도움이 된다.\n",
    "* 훈련과 검증 결과가 모두 성능이 좋지 않다면 과소적합(under-fitting)을 의심해볼 수 있다. 과소적합 상황에서는 네트워크 구조를 변경하거나 훈련을 늘리기 위해 에포크 수를 조정해 볼 수 있다.\n",
    "* 훈련 성능이 검증을 넘어서는 변곡점이 있다면 조기 종료를 고려할 수 있다.\n",
    "\n",
    "#### *가중치\n",
    "가중치에 대한 초깃값은 작은 난수를 사용한다. 작은 난수라는 숫자가 애매하다면 오토인코더 같은 비지도 학습을 통하여 사전 훈련(가중치 정보를 얻기 위한 사전훈련)을 진행한 후 지도 학습을 진행하는 것도 방법이다.\n",
    "\n",
    "#### *학습률\n",
    "학습률은 모델의 네트워크 구성에 따라 다르기 떄문에 초기에 매우 크거나 작은 임의의 난수를 선택하여 학습 결과를 보고 조금씩 변경한다. 이때 네트워크의 계층이 많다면 학습률은 높아야 하며, 네트워크의 계층이 몇 개 되지 않는다면 학습률은 작게 설정한다.\n",
    "\n",
    "#### *활성화 함수\n",
    "활성화 함수의 변경은 신중해야 한다. 활성화 함수를 변경할 때 손실 함수도 함께 변경해야 하는 경우가 많기 때문이다. 따라서 다루고자 하는 데이터 유형 및 데이터로 어떤 결과를 얻고 싶은지 정확하게 이해하지 못했다면 활성화 함수의 변경은 신중해야 한다. 일반적으로는 활성화 함수로 시그모이드나 하이퍼볼릭 탄젠트를 사용했다면 출력층에서는 소프트맥스나 시그모이드 함수를 많이 사용한다.\n",
    "\n",
    "#### *배치와 에포크\n",
    "일반적으로 큰 에포크와 작은 배치를 사용하는 것이 최근 딥러닝의 트렌드이기는 하지만, 적절한 배치 크기를 위해 훈련 데이터셋의 크기와 동일하게 하거나 하나의 배치로 훈련을 시켜보는 등 다양한 테스트를 진행하는 것이 좋다.\n",
    "\n",
    "#### *옵티마이저 및 손실 함수\n",
    "일반적으로 옵티마이저는 확률적 경사하강법을 많이 사용한다. 네트워크 구성에 따라 차이는 있지만 아담(Adam)이나 알엠에스프롬(RMSProp) 등도 좋은 성능을 보인다. 하지만 이것 역시 다양한 옵티마이저와 손실 함수를 적용해보고 성능이 최고인 것을 선택해야 한다.\n",
    "\n",
    "#### *네트워크 구성\n",
    "네트워크 구성은 네트워크 토폴로지(topology)라고도 한다. 최적의 네트워크를 구성하는 것 역시 쉽게 알 수 있는 부분이 아니므로 네트워크 구성을 변경해 가면서 성능을 테스트 해봐야한다. 예를 들어 하나의 은닉층에 뉴런을 여러 개 포함시키거나(네트워크가 넓다고 표현) 네트워크 계층을 늘리되 뉴런 개수는 줄여본다.(네트워크가 깊다고 표현) 혹은 두 가지를 결합하는 방법으로 최적의 네트워크가 무엇인지 확인한 후 네트워크를 결정해야 한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.1.4 앙상블을 이용한 성능 최적화"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙상블은 간단히 모델을 두 개 이상 섞어서 사용하는 것이다. 앙상블을 이용하는 것도 성능 향상에 도움 된다.\n",
    "\n",
    "알고리즘 튜닝을 위한 성능 최적화 방법은 하이퍼파리미터에 대한 경우의 수를 모두 고려해야 하기 때문에 모델 훈련이 수십 번에서 수백 번 필요할 수 있다.  \n",
    "따라서 성능 향상은 단시간에 해결되는 것이 아니고, 수많은 시행착오를 거처야 한다. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
